{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Trees in Practice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment we will explore various techniques for preventing overfitting in decision trees. We will extend the implementation of the binary decision trees that we implemented in the previous assignment. You will have to use your solutions from this previous assignment and extend them.\n",
    "\n",
    "In this assignment you will:\n",
    "\n",
    "* Implement binary decision trees with different early stopping methods.\n",
    "* Compare models with different stopping parameters.\n",
    "* Visualize the concept of overfitting in decision trees.\n",
    "\n",
    "Let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fire up GraphLab Create"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure you have the latest version of GraphLab Create."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A newer version of GraphLab Create (v1.10.1) is available! Your current version is v1.8.3.\n",
      "\n",
      "You can use pip to upgrade the graphlab-create package. For more information see https://dato.com/products/create/upgrade.\n"
     ]
    }
   ],
   "source": [
    "import graphlab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load LendingClub Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This assignment will use the [LendingClub](https://www.lendingclub.com/) dataset used in the previous two assignments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] GraphLab Create v1.8.3 started. Logging: /tmp/graphlab_server_1466118744.log\n"
     ]
    }
   ],
   "source": [
    "loans = graphlab.SFrame('lending-club-data.gl/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before, we reassign the labels to have +1 for a safe loan, and -1 for a risky (bad) loan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loans['safe_loans'] = loans['bad_loans'].apply(lambda x : +1 if x==0 else -1)\n",
    "loans = loans.remove_column('bad_loans')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using the same 4 categorical features as in the previous assignment: \n",
    "1. grade of the loan \n",
    "2. the length of the loan term\n",
    "3. the home ownership status: own, mortgage, rent\n",
    "4. number of years of employment.\n",
    "\n",
    "In the dataset, each of these features is a categorical feature. Since we are building a binary decision tree, we will have to convert this to binary data in a subsequent section using 1-hot encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features = ['grade',              # grade of the loan\n",
    "            'term',               # the term of the loan\n",
    "            'home_ownership',     # home_ownership status: own, mortgage or rent\n",
    "            'emp_length',         # number of years of employment\n",
    "           ]\n",
    "target = 'safe_loans'\n",
    "loans = loans[features + [target]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subsample dataset to make sure classes are balanced"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just as we did in the previous assignment, we will undersample the larger class (safe loans) in order to balance out our dataset. This means we are throwing away many data points. We used `seed = 1` so everyone gets the same results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of safe loans                 : 0.502236174422\n",
      "Percentage of risky loans                : 0.497763825578\n",
      "Total number of loans in our new dataset : 46508\n"
     ]
    }
   ],
   "source": [
    "safe_loans_raw = loans[loans[target] == 1]\n",
    "risky_loans_raw = loans[loans[target] == -1]\n",
    "\n",
    "# Since there are less risky loans than safe loans, find the ratio of the sizes\n",
    "# and use that percentage to undersample the safe loans.\n",
    "percentage = len(risky_loans_raw)/float(len(safe_loans_raw))\n",
    "safe_loans = safe_loans_raw.sample(percentage, seed = 1)\n",
    "risky_loans = risky_loans_raw\n",
    "loans_data = risky_loans.append(safe_loans)\n",
    "\n",
    "print \"Percentage of safe loans                 :\", len(safe_loans) / float(len(loans_data))\n",
    "print \"Percentage of risky loans                :\", len(risky_loans) / float(len(loans_data))\n",
    "print \"Total number of loans in our new dataset :\", len(loans_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** There are many approaches for dealing with imbalanced data, including some where we modify the learning algorithm. These approaches are beyond the scope of this course, but some of them are reviewed in this [paper](http://ieeexplore.ieee.org/xpl/login.jsp?tp=&arnumber=5128907&url=http%3A%2F%2Fieeexplore.ieee.org%2Fiel5%2F69%2F5173046%2F05128907.pdf%3Farnumber%3D5128907 ). For this assignment, we use the simplest possible approach, where we subsample the overly represented class to get a more balanced dataset. In general, and especially when the data is highly imbalanced, we recommend using more advanced methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform categorical data into binary features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are implementing **binary decision trees**, we transform our categorical data into binary data using 1-hot encoding, just as in the previous assignment. Here is the summary of that discussion:\n",
    "\n",
    "For instance, the **home_ownership** feature represents the home ownership status of the loanee, which is either `own`, `mortgage` or `rent`. For example, if a data point has the feature \n",
    "```\n",
    "   {'home_ownership': 'RENT'}\n",
    "```\n",
    "we want to turn this into three features: \n",
    "```\n",
    " { \n",
    "   'home_ownership = OWN'      : 0, \n",
    "   'home_ownership = MORTGAGE' : 0, \n",
    "   'home_ownership = RENT'     : 1\n",
    " }\n",
    "```\n",
    "\n",
    "Since this code requires a few Python and GraphLab tricks, feel free to use this block of code as is. Refer to the API documentation for a deeper understanding.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loans_data = risky_loans.append(safe_loans)\n",
    "for feature in features:\n",
    "    loans_data_one_hot_encoded = loans_data[feature].apply(lambda x: {x: 1})    \n",
    "    loans_data_unpacked = loans_data_one_hot_encoded.unpack(column_name_prefix=feature)\n",
    "    \n",
    "    # Change None's to 0's\n",
    "    for column in loans_data_unpacked.column_names():\n",
    "        loans_data_unpacked[column] = loans_data_unpacked[column].fillna(0)\n",
    "\n",
    "    loans_data.remove_column(feature)\n",
    "    loans_data.add_columns(loans_data_unpacked)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The feature columns now look like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['grade.A',\n",
       " 'grade.B',\n",
       " 'grade.C',\n",
       " 'grade.D',\n",
       " 'grade.E',\n",
       " 'grade.F',\n",
       " 'grade.G',\n",
       " 'term. 36 months',\n",
       " 'term. 60 months',\n",
       " 'home_ownership.MORTGAGE',\n",
       " 'home_ownership.OTHER',\n",
       " 'home_ownership.OWN',\n",
       " 'home_ownership.RENT',\n",
       " 'emp_length.1 year',\n",
       " 'emp_length.10+ years',\n",
       " 'emp_length.2 years',\n",
       " 'emp_length.3 years',\n",
       " 'emp_length.4 years',\n",
       " 'emp_length.5 years',\n",
       " 'emp_length.6 years',\n",
       " 'emp_length.7 years',\n",
       " 'emp_length.8 years',\n",
       " 'emp_length.9 years',\n",
       " 'emp_length.< 1 year',\n",
       " 'emp_length.n/a']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = loans_data.column_names()\n",
    "features.remove('safe_loans')  # Remove the response variable\n",
    "features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-Validation split\n",
    "\n",
    "We split the data into a train-validation split with 80% of the data in the training set and 20% of the data in the validation set. We use `seed=1` so that everyone gets the same result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data, validation_set = loans_data.random_split(.8, seed=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Early stopping methods for decision trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will extend the **binary tree implementation** from the previous assignment in order to handle some early stopping conditions. Recall the 3 early stopping methods that were discussed in lecture:\n",
    "\n",
    "1. Reached a **maximum depth**. (set by parameter `max_depth`).\n",
    "2. Reached a **minimum node size**. (set by parameter `min_node_size`).\n",
    "3. Don't split if the **gain in error reduction** is too small. (set by parameter `min_error_reduction`).\n",
    "\n",
    "For the rest of this assignment, we will refer to these three as **early stopping conditions 1, 2, and 3**.\n",
    "\n",
    "## Early stopping condition 1: Maximum depth\n",
    "\n",
    "Recall that we already implemented the maximum depth stopping condition in the previous assignment. In this assignment, we will experiment with this condition a bit more and also write code to implement the 2nd and 3rd early stopping conditions.\n",
    "\n",
    "We will be reusing code from the previous assignment and then building upon this.  We will **alert you** when you reach a function that was part of the previous assignment so that you can simply copy and past your previous code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Early stopping condition 2: Minimum node size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function **reached_minimum_node_size** takes 2 arguments:\n",
    "\n",
    "1. The `data` (from a node)\n",
    "2. The minimum number of data points that a node is allowed to split on, `min_node_size`.\n",
    "\n",
    "This function simply calculates whether the number of data points at a given node is less than or equal to the specified minimum node size. This function will be used to detect this early stopping condition in the **decision_tree_create** function.\n",
    "\n",
    "Fill in the parts of the function below where you find `## YOUR CODE HERE`.  There is **one** instance in the function below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reached_minimum_node_size(data, min_node_size):\n",
    "    # Return True if the number of data points is less than or equal to the minimum node size.\n",
    "    ## YOUR CODE HERE\n",
    "    return len(data) <= min_node_size\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Quiz question:** Given an intermediate node with 6 safe loans and 3 risky loans, if the `min_node_size` parameter is 10, what should the tree learning algorithm do next?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a leaf and return it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Early stopping condition 3: Minimum gain in error reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function **error_reduction** takes 2 arguments:\n",
    "\n",
    "1. The error **before** a split, `error_before_split`.\n",
    "2. The error **after** a split, `error_after_split`.\n",
    "\n",
    "This function computes the gain in error reduction, i.e., the difference between the error before the split and that after the split. This function will be used to detect this early stopping condition in the **decision_tree_create** function.\n",
    "\n",
    "Fill in the parts of the function below where you find `## YOUR CODE HERE`.  There is **one** instance in the function below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def error_reduction(error_before_split, error_after_split):\n",
    "    # Return the error before the split minus the error after the split.\n",
    "    ## YOUR CODE HERE\n",
    "    return error_before_split - error_after_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Quiz question:** Assume an intermediate node has 6 safe loans and 3 risky loans.  For each of 4 possible features to split on, the error reduction is 0.0, 0.05, 0.1, and 0.14, respectively. If the **minimum gain in error reduction** parameter is set to 0.2, what should the tree learning algorithm do next?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a leaf and return it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grabbing binary decision tree helper functions from past assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall from the previous assignment that we wrote a function `intermediate_node_num_mistakes` that calculates the number of **misclassified examples** when predicting the **majority class**. This is used to help determine which feature is best to split on at a given node of the tree.\n",
    "\n",
    "**Please copy and paste your code for `intermediate_node_num_mistakes` here**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def intermediate_node_num_mistakes(labels_in_node):\n",
    "    # Corner case: If labels_in_node is empty, return 0\n",
    "    if len(labels_in_node) == 0:\n",
    "        return 0\n",
    "    \n",
    "    # Count the number of 1's (safe loans)\n",
    "    ## YOUR CODE HERE\n",
    "    safe_loans_count = sum(labels_in_node == 1)\n",
    "    \n",
    "    # Count the number of -1's (risky loans)\n",
    "    ## YOUR CODE HERE\n",
    "    risky_loans_count = sum(labels_in_node == -1)\n",
    "                \n",
    "    # Return the number of mistakes that the majority classifier makes.\n",
    "    ## YOUR CODE HERE\n",
    "    return min(safe_loans_count, risky_loans_count)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then wrote a function `best_splitting_feature` that finds the best feature to split on given the data and a list of features to consider.\n",
    "\n",
    "**Please copy and paste your `best_splitting_feature` code here**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def best_splitting_feature(data, features, target):\n",
    "    \n",
    "    target_values = data[target]\n",
    "    best_feature = None # Keep track of the best feature \n",
    "    best_error = 10     # Keep track of the best error so far \n",
    "    # Note: Since error is always <= 1, we should intialize it with something larger than 1.\n",
    "\n",
    "    # Convert to float to make sure error gets computed correctly.\n",
    "    num_data_points = float(len(data))  \n",
    "    \n",
    "    # Loop through each feature to consider splitting on that feature\n",
    "    for feature in features:\n",
    "        \n",
    "        # The left split will have all data points where the feature value is 0\n",
    "        left_split = data[data[feature] == 0]\n",
    "        \n",
    "        # The right split will have all data points where the feature value is 1\n",
    "        ## YOUR CODE HERE\n",
    "        right_split = data[data[feature] == 1]   \n",
    "            \n",
    "        # Calculate the number of misclassified examples in the left split.\n",
    "        # Remember that we implemented a function for this! (It was called intermediate_node_num_mistakes)\n",
    "        # YOUR CODE HERE\n",
    "        left_mistakes = intermediate_node_num_mistakes(left_split[target])            \n",
    "\n",
    "        # Calculate the number of misclassified examples in the right split.\n",
    "        ## YOUR CODE HERE\n",
    "        right_mistakes = intermediate_node_num_mistakes(right_split[target])\n",
    "            \n",
    "        # Compute the classification error of this split.\n",
    "        # Error = (# of mistakes (left) + # of mistakes (right)) / (# of data points)\n",
    "        ## YOUR CODE HERE\n",
    "        error = (left_mistakes + right_mistakes)/num_data_points\n",
    "\n",
    "        # If this is the best error we have found so far, store the feature as best_feature and the error as best_error\n",
    "        ## YOUR CODE HERE\n",
    "        if error < best_error:\n",
    "            error = best_error\n",
    "            best_feature = feature\n",
    "            \n",
    "    return best_feature # Return the best feature we found"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, recall the function `create_leaf` from the previous assignment, which creates a leaf node given a set of target values.  \n",
    "\n",
    "**Please copy and paste your `create_leaf` code here**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_leaf(target_values):\n",
    "    \n",
    "    # Create a leaf node\n",
    "    leaf = {'splitting_feature' : None,\n",
    "            'left' : None,\n",
    "            'right' : None,\n",
    "            'is_leaf': True}   ## YOUR CODE HERE\n",
    "    \n",
    "    # Count the number of data points that are +1 and -1 in this node.\n",
    "    num_ones = len(target_values[target_values == +1])\n",
    "    num_minus_ones = len(target_values[target_values == -1])\n",
    "    \n",
    "    # For the leaf node, set the prediction to be the majority class.\n",
    "    # Store the predicted class (1 or -1) in leaf['prediction']\n",
    "    if num_ones > num_minus_ones:\n",
    "        leaf['prediction'] = +1         ## YOUR CODE HERE\n",
    "    else:\n",
    "        leaf['prediction'] = -1         ## YOUR CODE HERE\n",
    "        \n",
    "    # Return the leaf node        \n",
    "    return leaf "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Incorporating new early stopping conditions in binary decision tree implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, you will implement a function that builds a decision tree handling the three early stopping conditions described in this assignment.  In particular, you will write code to detect early stopping conditions 2 and 3.  You implemented above the functions needed to detect these conditions.  The 1st early stopping condition, **max_depth**, was implemented in the previous assigment and you will not need to reimplement this.  In addition to these early stopping conditions, the typical stopping conditions of having no mistakes or no more features to split on (which we denote by \"stopping conditions\" 1 and 2) are also included as in the previous assignment.\n",
    "\n",
    "**Implementing early stopping condition 2: minimum node size:**\n",
    "\n",
    "* **Step 1:** Use the function **reached_minimum_node_size** that you implemented earlier to write an if condition to detect whether we have hit the base case, i.e., the node does not have enough data points and should be turned into a leaf. Don't forget to use the `min_node_size` argument.\n",
    "* **Step 2:** Return a leaf. This line of code should be the same as the other (pre-implemented) stopping conditions.\n",
    "\n",
    "\n",
    "**Implementing early stopping condition 3: minimum error reduction:**\n",
    "\n",
    "**Note:** This has to come after finding the best splitting feature so we can calculate the error after splitting in order to calculate the error reduction.\n",
    "\n",
    "* **Step 1:** Calculate the **classification error before splitting**.  Recall that classification error is defined as:\n",
    "\n",
    "$$\n",
    "\\text{classification error} = \\frac{\\text{# mistakes}}{\\text{# total examples}}\n",
    "$$\n",
    "* **Step 2:** Calculate the **classification error after splitting**. This requires calculating the number of mistakes in the left and right splits, and then dividing by the total number of examples.\n",
    "* **Step 3:** Use the function **error_reduction** to that you implemented earlier to write an if condition to detect whether  the reduction in error is less than the constant provided (`min_error_reduction`). Don't forget to use that argument.\n",
    "* **Step 4:** Return a leaf. This line of code should be the same as the other (pre-implemented) stopping conditions.\n",
    "\n",
    "Fill in the places where you find `## YOUR CODE HERE`. There are **seven** places in this function for you to fill in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def decision_tree_create(data, features, target, current_depth = 0, \n",
    "                         max_depth = 10, min_node_size=1, \n",
    "                         min_error_reduction=0.0):\n",
    "    \n",
    "    remaining_features = features[:] # Make a copy of the features.\n",
    "    \n",
    "    target_values = data[target]\n",
    "    print \"--------------------------------------------------------------------\"\n",
    "    print \"Subtree, depth = %s (%s data points).\" % (current_depth, len(target_values))\n",
    "    \n",
    "    \n",
    "    # Stopping condition 1: All nodes are of the same type.\n",
    "    if intermediate_node_num_mistakes(target_values) == 0:\n",
    "        print \"Stopping condition 1 reached. All data points have the same target value.\"                \n",
    "        return create_leaf(target_values)\n",
    "    \n",
    "    # Stopping condition 2: No more features to split on.\n",
    "    if remaining_features == []:\n",
    "        print \"Stopping condition 2 reached. No remaining features.\"                \n",
    "        return create_leaf(target_values)    \n",
    "    \n",
    "    # Early stopping condition 1: Reached max depth limit.\n",
    "    if current_depth >= max_depth:\n",
    "        print \"Early stopping condition 1 reached. Reached maximum depth.\"\n",
    "        return create_leaf(target_values)\n",
    "    \n",
    "    # Early stopping condition 2: Reached the minimum node size.\n",
    "    # If the number of data points is less than or equal to the minimum size, return a leaf.\n",
    "    if reached_minimum_node_size(data, min_node_size): ## YOUR CODE HERE \n",
    "        print \"Early stopping condition 2 reached. Reached minimum node size.\"\n",
    "        return create_leaf(target_values)  ## YOUR CODE HERE\n",
    "    \n",
    "    # Find the best splitting feature\n",
    "    splitting_feature = best_splitting_feature(data, features, target)\n",
    "    \n",
    "    # Split on the best feature that we found. \n",
    "    left_split = data[data[splitting_feature] == 0]\n",
    "    right_split = data[data[splitting_feature] == 1]\n",
    "    \n",
    "    # Early stopping condition 3: Minimum error reduction\n",
    "    # Calculate the error before splitting (number of misclassified examples \n",
    "    # divided by the total number of examples)\n",
    "    error_before_split = intermediate_node_num_mistakes(target_values) / float(len(data))\n",
    "    \n",
    "    # Calculate the error after splitting (number of misclassified examples \n",
    "    # in both groups divided by the total number of examples)\n",
    "    left_mistakes = intermediate_node_num_mistakes(left_split[target])  ## YOUR CODE HERE\n",
    "    right_mistakes = intermediate_node_num_mistakes(right_split[target])  ## YOUR CODE HERE\n",
    "    error_after_split = (left_mistakes + right_mistakes) / float(len(data))\n",
    "    \n",
    "    # If the error reduction is LESS THAN OR EQUAL TO min_error_reduction, return a leaf.\n",
    "    if error_reduction(error_before_split, error_after_split) <= min_error_reduction: ## YOUR CODE HERE\n",
    "        print \"Early stopping condition 3 reached. Minimum error reduction.\"\n",
    "        return create_leaf(target_values)  ## YOUR CODE HERE \n",
    "    \n",
    "    \n",
    "    remaining_features.remove(splitting_feature)\n",
    "    print \"Split on feature %s. (%s, %s)\" % (\\\n",
    "                      splitting_feature, len(left_split), len(right_split))\n",
    "    \n",
    "    \n",
    "    # Repeat (recurse) on left and right subtrees\n",
    "    left_tree = decision_tree_create(left_split, remaining_features, target, \n",
    "                                     current_depth + 1, max_depth, min_node_size, min_error_reduction)        \n",
    "    \n",
    "    ## YOUR CODE HERE\n",
    "    right_tree = decision_tree_create(right_split, remaining_features, target,\n",
    "                                     current_depth + 1, max_depth, min_node_size, min_error_reduction)\n",
    "    \n",
    "    \n",
    "    return {'is_leaf'          : False, \n",
    "            'prediction'       : None,\n",
    "            'splitting_feature': splitting_feature,\n",
    "            'left'             : left_tree, \n",
    "            'right'            : right_tree}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a function to count the nodes in your tree:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count_nodes(tree):\n",
    "    if tree['is_leaf']:\n",
    "        return 1\n",
    "    return 1 + count_nodes(tree['left']) + count_nodes(tree['right'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following test code to check your implementation. Make sure you get **'Test passed'** before proceeding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 0 (37224 data points).\n",
      "Split on feature emp_length.n/a. (35781, 1443)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (35781 data points).\n",
      "Early stopping condition 3 reached. Minimum error reduction.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (1443 data points).\n",
      "Early stopping condition 3 reached. Minimum error reduction.\n",
      "Test failed... try again!\n",
      "Number of nodes found                : 3\n",
      "Number of nodes that should be there : 7\n"
     ]
    }
   ],
   "source": [
    "small_decision_tree = decision_tree_create(train_data, features, 'safe_loans', max_depth = 2, \n",
    "                                        min_node_size = 10, min_error_reduction=0.0)\n",
    "if count_nodes(small_decision_tree) == 7:\n",
    "    print 'Test passed!'\n",
    "else:\n",
    "    print 'Test failed... try again!'\n",
    "    print 'Number of nodes found                :', count_nodes(small_decision_tree)\n",
    "    print 'Number of nodes that should be there : 7' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a tree!\n",
    "\n",
    "Now that your code is working, we will train a tree model on the **train_data** with\n",
    "* `max_depth = 6`\n",
    "* `min_node_size = 100`, \n",
    "* `min_error_reduction = 0.0`\n",
    "\n",
    "**Warning**: This code block may take a minute to learn. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 0 (37224 data points).\n",
      "Split on feature emp_length.n/a. (35781, 1443)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (35781 data points).\n",
      "Split on feature emp_length.< 1 year. (32427, 3354)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (32427 data points).\n",
      "Split on feature emp_length.9 years. (31092, 1335)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (31092 data points).\n",
      "Split on feature emp_length.8 years. (29475, 1617)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (29475 data points).\n",
      "Split on feature emp_length.7 years. (27447, 2028)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (27447 data points).\n",
      "Split on feature emp_length.6 years. (25128, 2319)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (25128 data points).\n",
      "Early stopping condition 1 reached. Reached maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (2319 data points).\n",
      "Early stopping condition 1 reached. Reached maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (2028 data points).\n",
      "Split on feature emp_length.6 years. (2028, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (2028 data points).\n",
      "Early stopping condition 1 reached. Reached maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (1617 data points).\n",
      "Split on feature emp_length.7 years. (1617, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (1617 data points).\n",
      "Split on feature emp_length.6 years. (1617, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (1617 data points).\n",
      "Early stopping condition 1 reached. Reached maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (1335 data points).\n",
      "Split on feature emp_length.8 years. (1335, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (1335 data points).\n",
      "Split on feature emp_length.7 years. (1335, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (1335 data points).\n",
      "Split on feature emp_length.6 years. (1335, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (1335 data points).\n",
      "Early stopping condition 1 reached. Reached maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (3354 data points).\n",
      "Split on feature emp_length.9 years. (3354, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (3354 data points).\n",
      "Split on feature emp_length.8 years. (3354, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (3354 data points).\n",
      "Split on feature emp_length.7 years. (3354, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (3354 data points).\n",
      "Split on feature emp_length.6 years. (3354, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (3354 data points).\n",
      "Early stopping condition 1 reached. Reached maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (1443 data points).\n",
      "Split on feature emp_length.< 1 year. (1443, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (1443 data points).\n",
      "Split on feature emp_length.9 years. (1443, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (1443 data points).\n",
      "Split on feature emp_length.8 years. (1443, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (1443 data points).\n",
      "Split on feature emp_length.7 years. (1443, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (1443 data points).\n",
      "Split on feature emp_length.6 years. (1443, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (1443 data points).\n",
      "Early stopping condition 1 reached. Reached maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n"
     ]
    }
   ],
   "source": [
    "my_decision_tree_new = decision_tree_create(train_data, features, 'safe_loans', max_depth = 6, \n",
    "                                min_node_size = 100, min_error_reduction=0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now train a tree model **ignoring early stopping conditions 2 and 3** so that we get the same tree as in the previous assignment.  To ignore these conditions, we set `min_node_size=0` and `min_error_reduction=-1` (a negative value)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 0 (37224 data points).\n",
      "Split on feature emp_length.n/a. (35781, 1443)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (35781 data points).\n",
      "Split on feature emp_length.< 1 year. (32427, 3354)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (32427 data points).\n",
      "Split on feature emp_length.9 years. (31092, 1335)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (31092 data points).\n",
      "Split on feature emp_length.8 years. (29475, 1617)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (29475 data points).\n",
      "Split on feature emp_length.7 years. (27447, 2028)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (27447 data points).\n",
      "Split on feature emp_length.6 years. (25128, 2319)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (25128 data points).\n",
      "Early stopping condition 1 reached. Reached maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (2319 data points).\n",
      "Early stopping condition 1 reached. Reached maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (2028 data points).\n",
      "Split on feature emp_length.6 years. (2028, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (2028 data points).\n",
      "Early stopping condition 1 reached. Reached maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (1617 data points).\n",
      "Split on feature emp_length.7 years. (1617, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (1617 data points).\n",
      "Split on feature emp_length.6 years. (1617, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (1617 data points).\n",
      "Early stopping condition 1 reached. Reached maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (1335 data points).\n",
      "Split on feature emp_length.8 years. (1335, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (1335 data points).\n",
      "Split on feature emp_length.7 years. (1335, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (1335 data points).\n",
      "Split on feature emp_length.6 years. (1335, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (1335 data points).\n",
      "Early stopping condition 1 reached. Reached maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (3354 data points).\n",
      "Split on feature emp_length.9 years. (3354, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (3354 data points).\n",
      "Split on feature emp_length.8 years. (3354, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (3354 data points).\n",
      "Split on feature emp_length.7 years. (3354, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (3354 data points).\n",
      "Split on feature emp_length.6 years. (3354, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (3354 data points).\n",
      "Early stopping condition 1 reached. Reached maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (1443 data points).\n",
      "Split on feature emp_length.< 1 year. (1443, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (1443 data points).\n",
      "Split on feature emp_length.9 years. (1443, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (1443 data points).\n",
      "Split on feature emp_length.8 years. (1443, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (1443 data points).\n",
      "Split on feature emp_length.7 years. (1443, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (1443 data points).\n",
      "Split on feature emp_length.6 years. (1443, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (1443 data points).\n",
      "Early stopping condition 1 reached. Reached maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n"
     ]
    }
   ],
   "source": [
    "my_decision_tree_old = decision_tree_create(train_data, features, 'safe_loans', max_depth = 6, \n",
    "                                min_node_size = 0, min_error_reduction=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that in the previous assignment you implemented a function `classify` to classify a new point `x` using a given `tree`.\n",
    "\n",
    "**Please copy and paste your `classify` code here**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def classify(tree, x, annotate = False):   \n",
    "    # if the node is a leaf node.\n",
    "    if tree['is_leaf']:\n",
    "        if annotate: \n",
    "            print \"At leaf, predicting %s\" % tree['prediction']\n",
    "        return tree['prediction'] \n",
    "    else:\n",
    "        # split on feature.\n",
    "        split_feature_value = x[tree['splitting_feature']]\n",
    "        if annotate: \n",
    "            print \"Split on %s = %s\" % (tree['splitting_feature'], split_feature_value)\n",
    "        if split_feature_value == 0:\n",
    "            return classify(tree['left'], x, annotate)\n",
    "        else:\n",
    "            ### YOUR CODE HERE\n",
    "            return classify(tree['right'], x, annotate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's consider the first example of the validation set and see what the `my_decision_tree_new` model predicts for this data point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'emp_length.1 year': 0,\n",
       " 'emp_length.10+ years': 0,\n",
       " 'emp_length.2 years': 1,\n",
       " 'emp_length.3 years': 0,\n",
       " 'emp_length.4 years': 0,\n",
       " 'emp_length.5 years': 0,\n",
       " 'emp_length.6 years': 0,\n",
       " 'emp_length.7 years': 0,\n",
       " 'emp_length.8 years': 0,\n",
       " 'emp_length.9 years': 0,\n",
       " 'emp_length.< 1 year': 0,\n",
       " 'emp_length.n/a': 0,\n",
       " 'grade.A': 0,\n",
       " 'grade.B': 0,\n",
       " 'grade.C': 0,\n",
       " 'grade.D': 1,\n",
       " 'grade.E': 0,\n",
       " 'grade.F': 0,\n",
       " 'grade.G': 0,\n",
       " 'home_ownership.MORTGAGE': 0,\n",
       " 'home_ownership.OTHER': 0,\n",
       " 'home_ownership.OWN': 0,\n",
       " 'home_ownership.RENT': 1,\n",
       " 'safe_loans': -1,\n",
       " 'term. 36 months': 0,\n",
       " 'term. 60 months': 1}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_set[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: 1 \n"
     ]
    }
   ],
   "source": [
    "print 'Predicted class: %s ' % classify(my_decision_tree_new, validation_set[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's add some annotations to our prediction to see what the prediction path was that lead to this predicted class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split on emp_length.n/a = 0\n",
      "Split on emp_length.< 1 year = 0\n",
      "Split on emp_length.9 years = 0\n",
      "Split on emp_length.8 years = 0\n",
      "Split on emp_length.7 years = 0\n",
      "Split on emp_length.6 years = 0\n",
      "At leaf, predicting 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify(my_decision_tree_new, validation_set[0], annotate = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now recall the prediction path for the decision tree learned in the previous assignment, which we recreated here as `my_decision_tree_old`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split on emp_length.n/a = 0\n",
      "Split on emp_length.< 1 year = 0\n",
      "Split on emp_length.9 years = 0\n",
      "Split on emp_length.8 years = 0\n",
      "Split on emp_length.7 years = 0\n",
      "Split on emp_length.6 years = 0\n",
      "At leaf, predicting 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify(my_decision_tree_old, validation_set[0], annotate = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Quiz question:** For `my_decision_tree_new` trained with `max_depth = 6`, `min_node_size = 100`, `min_error_reduction=0.0`, is the prediction path for `validation_set[0]` shorter, longer, or the same as for `my_decision_tree_old` that ignored the early stopping conditions 2 and 3?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quiz question:** For `my_decision_tree_new` trained with `max_depth = 6`, `min_node_size = 100`, `min_error_reduction=0.0`, is the prediction path for **any point** always shorter, always longer, always the same, shorter or the same, or longer or the same as for `my_decision_tree_old` that ignored the early stopping conditions 2 and 3?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shorter or the Same"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Quiz question:** For a tree trained on **any** dataset using `max_depth = 6`, `min_node_size = 100`, `min_error_reduction=0.0`, what is the maximum number of splits encountered while making a single prediction?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let us evaluate the model that we have trained. You implemented this evautation in the function `evaluate_classification_error` from the previous assignment.\n",
    "\n",
    "**Please copy and paste your `evaluate_classification_error` code here**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate_classification_error(tree, data):\n",
    "    # Apply classify(tree, x) to each row in your data\n",
    "    prediction = data.apply(lambda x: classify(tree, x))\n",
    "    \n",
    "    # Once you've made the prediction, calculate the classification error\n",
    "    ## YOUR CODE HERE\n",
    "    return 1.0 * sum(prediction != data[target])/len(data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's use this function to evaluate the classification error of `my_decision_tree_new` on the **validation_set**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.48599741490736753"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_classification_error(my_decision_tree_new, validation_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, evaluate the validation error using `my_decision_tree_old`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.48599741490736753"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_classification_error(my_decision_tree_old, validation_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quiz question:** Is the validation error of the new decision tree (using early stopping conditions 2 and 3) lower than, higher than, or the same as that of the old decision tree from the previous assignment?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring the effect of max_depth\n",
    "\n",
    "We will compare three models trained with different values of the stopping criterion. We intentionally picked models at the extreme ends (**too small**, **just right**, and **too large**).\n",
    "\n",
    "Train three models with these parameters:\n",
    "\n",
    "1. **model_1**: max_depth = 2 (too small)\n",
    "2. **model_2**: max_depth = 6 (just right)\n",
    "3. **model_3**: max_depth = 14 (may be too large)\n",
    "\n",
    "For each of these three, we set `min_node_size = 0` and `min_error_reduction = -1`.\n",
    "\n",
    "** Note:** Each tree can take up to a few minutes to train. In particular, `model_3` will probably take the longest to train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 0 (37224 data points).\n",
      "Split on feature emp_length.n/a. (35781, 1443)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (35781 data points).\n",
      "Split on feature emp_length.< 1 year. (32427, 3354)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (32427 data points).\n",
      "Early stopping condition 1 reached. Reached maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (3354 data points).\n",
      "Early stopping condition 1 reached. Reached maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (1443 data points).\n",
      "Split on feature emp_length.< 1 year. (1443, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (1443 data points).\n",
      "Early stopping condition 1 reached. Reached maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 0 (37224 data points).\n",
      "Split on feature emp_length.n/a. (35781, 1443)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (35781 data points).\n",
      "Split on feature emp_length.< 1 year. (32427, 3354)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (32427 data points).\n",
      "Split on feature emp_length.9 years. (31092, 1335)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (31092 data points).\n",
      "Split on feature emp_length.8 years. (29475, 1617)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (29475 data points).\n",
      "Split on feature emp_length.7 years. (27447, 2028)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (27447 data points).\n",
      "Split on feature emp_length.6 years. (25128, 2319)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (25128 data points).\n",
      "Early stopping condition 1 reached. Reached maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (2319 data points).\n",
      "Early stopping condition 1 reached. Reached maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (2028 data points).\n",
      "Split on feature emp_length.6 years. (2028, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (2028 data points).\n",
      "Early stopping condition 1 reached. Reached maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (1617 data points).\n",
      "Split on feature emp_length.7 years. (1617, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (1617 data points).\n",
      "Split on feature emp_length.6 years. (1617, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (1617 data points).\n",
      "Early stopping condition 1 reached. Reached maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (1335 data points).\n",
      "Split on feature emp_length.8 years. (1335, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (1335 data points).\n",
      "Split on feature emp_length.7 years. (1335, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (1335 data points).\n",
      "Split on feature emp_length.6 years. (1335, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (1335 data points).\n",
      "Early stopping condition 1 reached. Reached maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (3354 data points).\n",
      "Split on feature emp_length.9 years. (3354, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (3354 data points).\n",
      "Split on feature emp_length.8 years. (3354, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (3354 data points).\n",
      "Split on feature emp_length.7 years. (3354, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (3354 data points).\n",
      "Split on feature emp_length.6 years. (3354, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (3354 data points).\n",
      "Early stopping condition 1 reached. Reached maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (1443 data points).\n",
      "Split on feature emp_length.< 1 year. (1443, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (1443 data points).\n",
      "Split on feature emp_length.9 years. (1443, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (1443 data points).\n",
      "Split on feature emp_length.8 years. (1443, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (1443 data points).\n",
      "Split on feature emp_length.7 years. (1443, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (1443 data points).\n",
      "Split on feature emp_length.6 years. (1443, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (1443 data points).\n",
      "Early stopping condition 1 reached. Reached maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 0 (37224 data points).\n",
      "Split on feature emp_length.n/a. (35781, 1443)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (35781 data points).\n",
      "Split on feature emp_length.< 1 year. (32427, 3354)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (32427 data points).\n",
      "Split on feature emp_length.9 years. (31092, 1335)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (31092 data points).\n",
      "Split on feature emp_length.8 years. (29475, 1617)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (29475 data points).\n",
      "Split on feature emp_length.7 years. (27447, 2028)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (27447 data points).\n",
      "Split on feature emp_length.6 years. (25128, 2319)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (25128 data points).\n",
      "Split on feature emp_length.5 years. (22251, 2877)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 7 (22251 data points).\n",
      "Split on feature emp_length.4 years. (19620, 2631)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 8 (19620 data points).\n",
      "Split on feature emp_length.3 years. (16495, 3125)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 9 (16495 data points).\n",
      "Split on feature emp_length.2 years. (12923, 3572)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 10 (12923 data points).\n",
      "Split on feature emp_length.10+ years. (2600, 10323)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 11 (2600 data points).\n",
      "Split on feature emp_length.1 year. (0, 2600)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 12 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 12 (2600 data points).\n",
      "Split on feature home_ownership.RENT. (1076, 1524)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 13 (1076 data points).\n",
      "Split on feature home_ownership.OWN. (887, 189)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 14 (887 data points).\n",
      "Early stopping condition 1 reached. Reached maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 14 (189 data points).\n",
      "Early stopping condition 1 reached. Reached maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 13 (1524 data points).\n",
      "Split on feature home_ownership.OWN. (1524, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 14 (1524 data points).\n",
      "Early stopping condition 1 reached. Reached maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 14 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 11 (10323 data points).\n",
      "Split on feature emp_length.1 year. (10323, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 12 (10323 data points).\n",
      "Split on feature home_ownership.RENT. (7118, 3205)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 13 (7118 data points).\n",
      "Split on feature home_ownership.OWN. (6278, 840)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 14 (6278 data points).\n",
      "Early stopping condition 1 reached. Reached maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 14 (840 data points).\n",
      "Early stopping condition 1 reached. Reached maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 13 (3205 data points).\n",
      "Split on feature home_ownership.OWN. (3205, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 14 (3205 data points).\n",
      "Early stopping condition 1 reached. Reached maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 14 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 12 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 10 (3572 data points).\n",
      "Split on feature emp_length.10+ years. (3572, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 11 (3572 data points).\n",
      "Split on feature emp_length.1 year. (3572, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 12 (3572 data points).\n",
      "Split on feature home_ownership.RENT. (1586, 1986)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 13 (1586 data points).\n",
      "Split on feature home_ownership.OWN. (1321, 265)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 14 (1321 data points).\n",
      "Early stopping condition 1 reached. Reached maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 14 (265 data points).\n",
      "Early stopping condition 1 reached. Reached maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 13 (1986 data points).\n",
      "Split on feature home_ownership.OWN. (1986, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 14 (1986 data points).\n",
      "Early stopping condition 1 reached. Reached maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 14 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 12 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 11 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 9 (3125 data points).\n",
      "Split on feature emp_length.2 years. (3125, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 10 (3125 data points).\n",
      "Split on feature emp_length.10+ years. (3125, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 11 (3125 data points).\n",
      "Split on feature emp_length.1 year. (3125, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 12 (3125 data points).\n",
      "Split on feature home_ownership.RENT. (1505, 1620)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 13 (1505 data points).\n",
      "Split on feature home_ownership.OWN. (1262, 243)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 14 (1262 data points).\n",
      "Early stopping condition 1 reached. Reached maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 14 (243 data points).\n",
      "Early stopping condition 1 reached. Reached maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 13 (1620 data points).\n",
      "Split on feature home_ownership.OWN. (1620, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 14 (1620 data points).\n",
      "Early stopping condition 1 reached. Reached maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 14 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 12 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 11 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 10 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 8 (2631 data points).\n",
      "Split on feature emp_length.3 years. (2631, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 9 (2631 data points).\n",
      "Split on feature emp_length.2 years. (2631, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 10 (2631 data points).\n",
      "Split on feature emp_length.10+ years. (2631, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 11 (2631 data points).\n",
      "Split on feature emp_length.1 year. (2631, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 12 (2631 data points).\n",
      "Split on feature home_ownership.RENT. (1293, 1338)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 13 (1293 data points).\n",
      "Split on feature home_ownership.OWN. (1079, 214)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 14 (1079 data points).\n",
      "Early stopping condition 1 reached. Reached maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 14 (214 data points).\n",
      "Early stopping condition 1 reached. Reached maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 13 (1338 data points).\n",
      "Split on feature home_ownership.OWN. (1338, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 14 (1338 data points).\n",
      "Early stopping condition 1 reached. Reached maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 14 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 12 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 11 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 10 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 9 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 7 (2877 data points).\n",
      "Split on feature emp_length.4 years. (2877, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 8 (2877 data points).\n",
      "Split on feature emp_length.3 years. (2877, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 9 (2877 data points).\n",
      "Split on feature emp_length.2 years. (2877, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 10 (2877 data points).\n",
      "Split on feature emp_length.10+ years. (2877, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 11 (2877 data points).\n",
      "Split on feature emp_length.1 year. (2877, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 12 (2877 data points).\n",
      "Split on feature home_ownership.RENT. (1516, 1361)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 13 (1516 data points).\n",
      "Split on feature home_ownership.OWN. (1293, 223)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 14 (1293 data points).\n",
      "Early stopping condition 1 reached. Reached maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 14 (223 data points).\n",
      "Early stopping condition 1 reached. Reached maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 13 (1361 data points).\n",
      "Split on feature home_ownership.OWN. (1361, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 14 (1361 data points).\n",
      "Early stopping condition 1 reached. Reached maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 14 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 12 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 11 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 10 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 9 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 8 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (2319 data points).\n",
      "Split on feature emp_length.5 years. (2319, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 7 (2319 data points).\n",
      "Split on feature emp_length.4 years. (2319, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 8 (2319 data points).\n",
      "Split on feature emp_length.3 years. (2319, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 9 (2319 data points).\n",
      "Split on feature emp_length.2 years. (2319, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 10 (2319 data points).\n",
      "Split on feature emp_length.10+ years. (2319, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 11 (2319 data points).\n",
      "Split on feature emp_length.1 year. (2319, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 12 (2319 data points).\n",
      "Split on feature home_ownership.RENT. (1252, 1067)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 13 (1252 data points).\n",
      "Split on feature home_ownership.OWN. (1079, 173)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 14 (1079 data points).\n",
      "Early stopping condition 1 reached. Reached maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 14 (173 data points).\n",
      "Early stopping condition 1 reached. Reached maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 13 (1067 data points).\n",
      "Split on feature home_ownership.OWN. (1067, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 14 (1067 data points).\n",
      "Early stopping condition 1 reached. Reached maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 14 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 12 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 11 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 10 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 9 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 8 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 7 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (2028 data points).\n",
      "Split on feature emp_length.6 years. (2028, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (2028 data points).\n",
      "Split on feature emp_length.5 years. (2028, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 7 (2028 data points).\n",
      "Split on feature emp_length.4 years. (2028, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 8 (2028 data points).\n",
      "Split on feature emp_length.3 years. (2028, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 9 (2028 data points).\n",
      "Split on feature emp_length.2 years. (2028, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 10 (2028 data points).\n",
      "Split on feature emp_length.10+ years. (2028, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 11 (2028 data points).\n",
      "Split on feature emp_length.1 year. (2028, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 12 (2028 data points).\n",
      "Split on feature home_ownership.RENT. (1192, 836)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 13 (1192 data points).\n",
      "Split on feature home_ownership.OWN. (1027, 165)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 14 (1027 data points).\n",
      "Early stopping condition 1 reached. Reached maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 14 (165 data points).\n",
      "Early stopping condition 1 reached. Reached maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 13 (836 data points).\n",
      "Split on feature home_ownership.OWN. (836, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 14 (836 data points).\n",
      "Early stopping condition 1 reached. Reached maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 14 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 12 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 11 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 10 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 9 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 8 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 7 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (1617 data points).\n",
      "Split on feature emp_length.7 years. (1617, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (1617 data points).\n",
      "Split on feature emp_length.6 years. (1617, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (1617 data points).\n",
      "Split on feature emp_length.5 years. (1617, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 7 (1617 data points).\n",
      "Split on feature emp_length.4 years. (1617, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 8 (1617 data points).\n",
      "Split on feature emp_length.3 years. (1617, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 9 (1617 data points).\n",
      "Split on feature emp_length.2 years. (1617, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 10 (1617 data points).\n",
      "Split on feature emp_length.10+ years. (1617, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 11 (1617 data points).\n",
      "Split on feature emp_length.1 year. (1617, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 12 (1617 data points).\n",
      "Split on feature home_ownership.RENT. (946, 671)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 13 (946 data points).\n",
      "Split on feature home_ownership.OWN. (829, 117)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 14 (829 data points).\n",
      "Early stopping condition 1 reached. Reached maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 14 (117 data points).\n",
      "Early stopping condition 1 reached. Reached maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 13 (671 data points).\n",
      "Split on feature home_ownership.OWN. (671, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 14 (671 data points).\n",
      "Early stopping condition 1 reached. Reached maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 14 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 12 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 11 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 10 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 9 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 8 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 7 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (1335 data points).\n",
      "Split on feature emp_length.8 years. (1335, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (1335 data points).\n",
      "Split on feature emp_length.7 years. (1335, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (1335 data points).\n",
      "Split on feature emp_length.6 years. (1335, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (1335 data points).\n",
      "Split on feature emp_length.5 years. (1335, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 7 (1335 data points).\n",
      "Split on feature emp_length.4 years. (1335, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 8 (1335 data points).\n",
      "Split on feature emp_length.3 years. (1335, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 9 (1335 data points).\n",
      "Split on feature emp_length.2 years. (1335, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 10 (1335 data points).\n",
      "Split on feature emp_length.10+ years. (1335, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 11 (1335 data points).\n",
      "Split on feature emp_length.1 year. (1335, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 12 (1335 data points).\n",
      "Split on feature home_ownership.RENT. (833, 502)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 13 (833 data points).\n",
      "Split on feature home_ownership.OWN. (728, 105)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 14 (728 data points).\n",
      "Early stopping condition 1 reached. Reached maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 14 (105 data points).\n",
      "Early stopping condition 1 reached. Reached maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 13 (502 data points).\n",
      "Split on feature home_ownership.OWN. (502, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 14 (502 data points).\n",
      "Early stopping condition 1 reached. Reached maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 14 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 12 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 11 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 10 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 9 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 8 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 7 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (3354 data points).\n",
      "Split on feature emp_length.9 years. (3354, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (3354 data points).\n",
      "Split on feature emp_length.8 years. (3354, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (3354 data points).\n",
      "Split on feature emp_length.7 years. (3354, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (3354 data points).\n",
      "Split on feature emp_length.6 years. (3354, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (3354 data points).\n",
      "Split on feature emp_length.5 years. (3354, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 7 (3354 data points).\n",
      "Split on feature emp_length.4 years. (3354, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 8 (3354 data points).\n",
      "Split on feature emp_length.3 years. (3354, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 9 (3354 data points).\n",
      "Split on feature emp_length.2 years. (3354, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 10 (3354 data points).\n",
      "Split on feature emp_length.10+ years. (3354, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 11 (3354 data points).\n",
      "Split on feature emp_length.1 year. (3354, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 12 (3354 data points).\n",
      "Split on feature home_ownership.RENT. (1328, 2026)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 13 (1328 data points).\n",
      "Split on feature home_ownership.OWN. (1040, 288)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 14 (1040 data points).\n",
      "Early stopping condition 1 reached. Reached maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 14 (288 data points).\n",
      "Early stopping condition 1 reached. Reached maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 13 (2026 data points).\n",
      "Split on feature home_ownership.OWN. (2026, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 14 (2026 data points).\n",
      "Early stopping condition 1 reached. Reached maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 14 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 12 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 11 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 10 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 9 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 8 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 7 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (1443 data points).\n",
      "Split on feature emp_length.< 1 year. (1443, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (1443 data points).\n",
      "Split on feature emp_length.9 years. (1443, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (1443 data points).\n",
      "Split on feature emp_length.8 years. (1443, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (1443 data points).\n",
      "Split on feature emp_length.7 years. (1443, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (1443 data points).\n",
      "Split on feature emp_length.6 years. (1443, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (1443 data points).\n",
      "Split on feature emp_length.5 years. (1443, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 7 (1443 data points).\n",
      "Split on feature emp_length.4 years. (1443, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 8 (1443 data points).\n",
      "Split on feature emp_length.3 years. (1443, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 9 (1443 data points).\n",
      "Split on feature emp_length.2 years. (1443, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 10 (1443 data points).\n",
      "Split on feature emp_length.10+ years. (1443, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 11 (1443 data points).\n",
      "Split on feature emp_length.1 year. (1443, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 12 (1443 data points).\n",
      "Split on feature home_ownership.RENT. (869, 574)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 13 (869 data points).\n",
      "Split on feature home_ownership.OWN. (616, 253)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 14 (616 data points).\n",
      "Early stopping condition 1 reached. Reached maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 14 (253 data points).\n",
      "Early stopping condition 1 reached. Reached maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 13 (574 data points).\n",
      "Split on feature home_ownership.OWN. (574, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 14 (574 data points).\n",
      "Early stopping condition 1 reached. Reached maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 14 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 12 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 11 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 10 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 9 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 8 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 7 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n"
     ]
    }
   ],
   "source": [
    "model_1 = decision_tree_create(train_data, features, 'safe_loans', max_depth = 2, \n",
    "                               min_node_size = 0, min_error_reduction=-1)\n",
    "model_2 = decision_tree_create(train_data, features, 'safe_loans', max_depth = 6, \n",
    "                                min_node_size = 0, min_error_reduction=-1)\n",
    "model_3 = decision_tree_create(train_data, features, 'safe_loans', max_depth = 14, \n",
    "                                min_node_size = 0, min_error_reduction=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the models\n",
    "\n",
    "Let us evaluate the models on the **train** and **validation** data. Let us start by evaluating the classification error on the training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data, classification error (model 1): 0.487561788094\n",
      "Training data, classification error (model 2): 0.483854502472\n",
      "Training data, classification error (model 3): 0.462067483344\n"
     ]
    }
   ],
   "source": [
    "print \"Training data, classification error (model 1):\", evaluate_classification_error(model_1, train_data)\n",
    "print \"Training data, classification error (model 2):\", evaluate_classification_error(model_2, train_data)\n",
    "print \"Training data, classification error (model 3):\", evaluate_classification_error(model_3, train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now evaluate the classification error on the validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation data, classification error (model 1): 0.49429125377\n",
      "Validation data, classification error (model 2): 0.485997414907\n",
      "Validation data, classification error (model 3): 0.465855234813\n"
     ]
    }
   ],
   "source": [
    "print \"Validation data, classification error (model 1):\", evaluate_classification_error(model_1, validation_set)\n",
    "print \"Validation data, classification error (model 2):\", evaluate_classification_error(model_2, validation_set)\n",
    "print \"Validation data, classification error (model 3):\", evaluate_classification_error(model_3, validation_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quiz Question:** Which tree has the smallest error on the validation data?\n",
    "\n",
    "**Quiz Question:** Does the tree with the smallest error in the training data also have the smallest error in the validation data?\n",
    "\n",
    "**Quiz Question:** Is it always true that the tree with the lowest classification error on the **training** set will result in the lowest classification error in the **validation** set?\n",
    "\n",
    "\n",
    "### Measuring the complexity of the tree\n",
    "\n",
    "Recall in the lecture that we talked about deeper trees being more complex. We will measure the complexity of the tree as\n",
    "\n",
    "```\n",
    "  complexity(T) = number of leaves in the tree T\n",
    "```\n",
    "\n",
    "Here, we provide a function `count_leaves` that counts the number of leaves in a tree. Using this implementation, compute the number of nodes in `model_1`, `model_2`, and `model_3`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count_leaves(tree):\n",
    "    if tree['is_leaf']:\n",
    "        return 1\n",
    "    return count_leaves(tree['left']) + count_leaves(tree['right'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the number of nodes in `model_1`, `model_2`, and `model_3`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leafs count (model 1): 4\n",
      "Leafs count (model 2): 22\n",
      "Leafs count (model 3): 115\n"
     ]
    }
   ],
   "source": [
    "print \"Leafs count (model 1):\", count_leaves(model_1)\n",
    "print \"Leafs count (model 2):\", count_leaves(model_2)\n",
    "print \"Leafs count (model 3):\", count_leaves(model_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quiz question:** Which tree has the largest complexity?\n",
    "    \n",
    "\n",
    "**Quiz question:** Is it always true that the most complex tree will result in the lowest classification error in the **validation_set**?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring the effect of min_error\n",
    "\n",
    "We will compare three models trained with different values of the stopping criterion. We intentionally picked models at the extreme ends (**negative**, **just right**, and **too positive**).\n",
    "\n",
    "Train three models with these parameters:\n",
    "1. **model_4**: `min_error_reduction = -1` (ignoring this early stopping condition)\n",
    "2. **model_5**: `min_error_reduction = 0` (just right)\n",
    "3. **model_6**: `min_error_reduction = 5` (too positive)\n",
    "\n",
    "For each of these three, we set `max_depth = 6`, and `min_node_size = 0`.\n",
    "\n",
    "** Note:** Each tree can take up to 30 seconds to train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 0 (37224 data points).\n",
      "Split on feature emp_length.n/a. (35781, 1443)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (35781 data points).\n",
      "Split on feature emp_length.< 1 year. (32427, 3354)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (32427 data points).\n",
      "Split on feature emp_length.9 years. (31092, 1335)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (31092 data points).\n",
      "Split on feature emp_length.8 years. (29475, 1617)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (29475 data points).\n",
      "Split on feature emp_length.7 years. (27447, 2028)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (27447 data points).\n",
      "Split on feature emp_length.6 years. (25128, 2319)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (25128 data points).\n",
      "Early stopping condition 1 reached. Reached maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (2319 data points).\n",
      "Early stopping condition 1 reached. Reached maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (2028 data points).\n",
      "Split on feature emp_length.6 years. (2028, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (2028 data points).\n",
      "Early stopping condition 1 reached. Reached maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (1617 data points).\n",
      "Split on feature emp_length.7 years. (1617, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (1617 data points).\n",
      "Split on feature emp_length.6 years. (1617, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (1617 data points).\n",
      "Early stopping condition 1 reached. Reached maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (1335 data points).\n",
      "Split on feature emp_length.8 years. (1335, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (1335 data points).\n",
      "Split on feature emp_length.7 years. (1335, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (1335 data points).\n",
      "Split on feature emp_length.6 years. (1335, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (1335 data points).\n",
      "Early stopping condition 1 reached. Reached maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (3354 data points).\n",
      "Split on feature emp_length.9 years. (3354, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (3354 data points).\n",
      "Split on feature emp_length.8 years. (3354, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (3354 data points).\n",
      "Split on feature emp_length.7 years. (3354, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (3354 data points).\n",
      "Split on feature emp_length.6 years. (3354, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (3354 data points).\n",
      "Early stopping condition 1 reached. Reached maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (1443 data points).\n",
      "Split on feature emp_length.< 1 year. (1443, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (1443 data points).\n",
      "Split on feature emp_length.9 years. (1443, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (1443 data points).\n",
      "Split on feature emp_length.8 years. (1443, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (1443 data points).\n",
      "Split on feature emp_length.7 years. (1443, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (1443 data points).\n",
      "Split on feature emp_length.6 years. (1443, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (1443 data points).\n",
      "Early stopping condition 1 reached. Reached maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 0 (37224 data points).\n",
      "Split on feature emp_length.n/a. (35781, 1443)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (35781 data points).\n",
      "Split on feature emp_length.< 1 year. (32427, 3354)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (32427 data points).\n",
      "Split on feature emp_length.9 years. (31092, 1335)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (31092 data points).\n",
      "Split on feature emp_length.8 years. (29475, 1617)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (29475 data points).\n",
      "Split on feature emp_length.7 years. (27447, 2028)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (27447 data points).\n",
      "Split on feature emp_length.6 years. (25128, 2319)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (25128 data points).\n",
      "Early stopping condition 1 reached. Reached maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (2319 data points).\n",
      "Early stopping condition 1 reached. Reached maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (2028 data points).\n",
      "Split on feature emp_length.6 years. (2028, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (2028 data points).\n",
      "Early stopping condition 1 reached. Reached maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (1617 data points).\n",
      "Split on feature emp_length.7 years. (1617, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (1617 data points).\n",
      "Split on feature emp_length.6 years. (1617, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (1617 data points).\n",
      "Early stopping condition 1 reached. Reached maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (1335 data points).\n",
      "Split on feature emp_length.8 years. (1335, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (1335 data points).\n",
      "Split on feature emp_length.7 years. (1335, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (1335 data points).\n",
      "Split on feature emp_length.6 years. (1335, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (1335 data points).\n",
      "Early stopping condition 1 reached. Reached maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (3354 data points).\n",
      "Split on feature emp_length.9 years. (3354, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (3354 data points).\n",
      "Split on feature emp_length.8 years. (3354, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (3354 data points).\n",
      "Split on feature emp_length.7 years. (3354, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (3354 data points).\n",
      "Split on feature emp_length.6 years. (3354, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (3354 data points).\n",
      "Early stopping condition 1 reached. Reached maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (1443 data points).\n",
      "Split on feature emp_length.< 1 year. (1443, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (1443 data points).\n",
      "Split on feature emp_length.9 years. (1443, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (1443 data points).\n",
      "Split on feature emp_length.8 years. (1443, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (1443 data points).\n",
      "Split on feature emp_length.7 years. (1443, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (1443 data points).\n",
      "Split on feature emp_length.6 years. (1443, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (1443 data points).\n",
      "Early stopping condition 1 reached. Reached maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 0 (37224 data points).\n",
      "Early stopping condition 3 reached. Minimum error reduction.\n"
     ]
    }
   ],
   "source": [
    "model_4 = decision_tree_create(train_data, features, 'safe_loans', max_depth = 6, \n",
    "                               min_node_size = 0, min_error_reduction=-1)\n",
    "model_5 = decision_tree_create(train_data, features, 'safe_loans', max_depth = 6, \n",
    "                               min_node_size = 0, min_error_reduction=0)\n",
    "model_6 = decision_tree_create(train_data, features, 'safe_loans', max_depth = 6, \n",
    "                               min_node_size = 0, min_error_reduction=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the accuracy of each model (**model_4**, **model_5**, or **model_6**) on the validation set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation data, classification error (model 4): 0.485997414907\n",
      "Validation data, classification error (model 5): 0.485997414907\n",
      "Validation data, classification error (model 6): 0.503446790177\n"
     ]
    }
   ],
   "source": [
    "print \"Validation data, classification error (model 4):\", evaluate_classification_error(model_4, validation_set)\n",
    "print \"Validation data, classification error (model 5):\", evaluate_classification_error(model_5, validation_set)\n",
    "print \"Validation data, classification error (model 6):\", evaluate_classification_error(model_6, validation_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the `count_leaves` function, compute the number of leaves in each of each models in (**model_4**, **model_5**, and **model_6**). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leafs count (model 4): 22\n",
      "Leafs count (model 5): 22\n",
      "Leafs count (model 6): 1\n"
     ]
    }
   ],
   "source": [
    "print \"Leafs count (model 4):\", count_leaves(model_4)\n",
    "print \"Leafs count (model 5):\", count_leaves(model_5)\n",
    "print \"Leafs count (model 6):\", count_leaves(model_6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quiz Question:** Using the complexity definition above, which model (**model_4**, **model_5**, or **model_6**) has the largest complexity?\n",
    "\n",
    "Did this match your expectation?\n",
    "\n",
    "**Quiz Question:** **model_4** and **model_5** have similar classification error on the validation set but **model_5** has lower complexity? Should you pick **model_5** over **model_4**?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring the effect of min_node_size\n",
    "\n",
    "We will compare three models trained with different values of the stopping criterion. Again, intentionally picked models at the extreme ends (**too small**, **just right**, and **just right**).\n",
    "\n",
    "Train three models with these parameters:\n",
    "1. **model_7**: min_node_size = 0 (too small)\n",
    "2. **model_8**: min_node_size = 2000 (just right)\n",
    "3. **model_9**: min_node_size = 50000 (too large)\n",
    "\n",
    "For each of these three, we set `max_depth = 6`, and `min_error_reduction = -1`.\n",
    "\n",
    "** Note:** Each tree can take up to 30 seconds to train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 0 (37224 data points).\n",
      "Split on feature emp_length.n/a. (35781, 1443)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (35781 data points).\n",
      "Split on feature emp_length.< 1 year. (32427, 3354)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (32427 data points).\n",
      "Split on feature emp_length.9 years. (31092, 1335)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (31092 data points).\n",
      "Split on feature emp_length.8 years. (29475, 1617)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (29475 data points).\n",
      "Split on feature emp_length.7 years. (27447, 2028)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (27447 data points).\n",
      "Split on feature emp_length.6 years. (25128, 2319)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (25128 data points).\n",
      "Early stopping condition 1 reached. Reached maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (2319 data points).\n",
      "Early stopping condition 1 reached. Reached maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (2028 data points).\n",
      "Split on feature emp_length.6 years. (2028, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (2028 data points).\n",
      "Early stopping condition 1 reached. Reached maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (1617 data points).\n",
      "Split on feature emp_length.7 years. (1617, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (1617 data points).\n",
      "Split on feature emp_length.6 years. (1617, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (1617 data points).\n",
      "Early stopping condition 1 reached. Reached maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (1335 data points).\n",
      "Split on feature emp_length.8 years. (1335, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (1335 data points).\n",
      "Split on feature emp_length.7 years. (1335, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (1335 data points).\n",
      "Split on feature emp_length.6 years. (1335, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (1335 data points).\n",
      "Early stopping condition 1 reached. Reached maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (3354 data points).\n",
      "Split on feature emp_length.9 years. (3354, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (3354 data points).\n",
      "Split on feature emp_length.8 years. (3354, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (3354 data points).\n",
      "Split on feature emp_length.7 years. (3354, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (3354 data points).\n",
      "Split on feature emp_length.6 years. (3354, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (3354 data points).\n",
      "Early stopping condition 1 reached. Reached maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (1443 data points).\n",
      "Split on feature emp_length.< 1 year. (1443, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (1443 data points).\n",
      "Split on feature emp_length.9 years. (1443, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (1443 data points).\n",
      "Split on feature emp_length.8 years. (1443, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (1443 data points).\n",
      "Split on feature emp_length.7 years. (1443, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (1443 data points).\n",
      "Split on feature emp_length.6 years. (1443, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (1443 data points).\n",
      "Early stopping condition 1 reached. Reached maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 0 (37224 data points).\n",
      "Split on feature emp_length.n/a. (35781, 1443)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (35781 data points).\n",
      "Split on feature emp_length.< 1 year. (32427, 3354)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (32427 data points).\n",
      "Split on feature emp_length.9 years. (31092, 1335)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (31092 data points).\n",
      "Split on feature emp_length.8 years. (29475, 1617)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (29475 data points).\n",
      "Split on feature emp_length.7 years. (27447, 2028)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (27447 data points).\n",
      "Split on feature emp_length.6 years. (25128, 2319)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (25128 data points).\n",
      "Early stopping condition 1 reached. Reached maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (2319 data points).\n",
      "Early stopping condition 1 reached. Reached maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (2028 data points).\n",
      "Split on feature emp_length.6 years. (2028, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (2028 data points).\n",
      "Early stopping condition 1 reached. Reached maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (1617 data points).\n",
      "Early stopping condition 2 reached. Reached minimum node size.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (1335 data points).\n",
      "Early stopping condition 2 reached. Reached minimum node size.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (3354 data points).\n",
      "Split on feature emp_length.9 years. (3354, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (3354 data points).\n",
      "Split on feature emp_length.8 years. (3354, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (3354 data points).\n",
      "Split on feature emp_length.7 years. (3354, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (3354 data points).\n",
      "Split on feature emp_length.6 years. (3354, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (3354 data points).\n",
      "Early stopping condition 1 reached. Reached maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (1443 data points).\n",
      "Early stopping condition 2 reached. Reached minimum node size.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 0 (37224 data points).\n",
      "Early stopping condition 2 reached. Reached minimum node size.\n"
     ]
    }
   ],
   "source": [
    "model_7 = decision_tree_create(train_data, features, 'safe_loans', max_depth = 6, \n",
    "                               min_node_size = 0, min_error_reduction=-1)\n",
    "model_8 = decision_tree_create(train_data, features, 'safe_loans', max_depth = 6, \n",
    "                               min_node_size = 2000, min_error_reduction=-1)\n",
    "model_9 = decision_tree_create(train_data, features, 'safe_loans', max_depth = 6, \n",
    "                               min_node_size = 50000, min_error_reduction=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let us evaluate the models (**model_7**, **model_8**, or **model_9**) on the **validation_set**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation data, classification error (model 7): 0.485997414907\n",
      "Validation data, classification error (model 8): 0.485997414907\n",
      "Validation data, classification error (model 9): 0.503446790177\n"
     ]
    }
   ],
   "source": [
    "print \"Validation data, classification error (model 7):\", evaluate_classification_error(model_7, validation_set)\n",
    "print \"Validation data, classification error (model 8):\", evaluate_classification_error(model_8, validation_set)\n",
    "print \"Validation data, classification error (model 9):\", evaluate_classification_error(model_9, validation_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the `count_leaves` function, compute the number of leaves in each of each models (**model_7**, **model_8**, and **model_9**). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leafs count (model 7): 22\n",
      "Leafs count (model 8): 12\n",
      "Leafs count (model 9): 1\n"
     ]
    }
   ],
   "source": [
    "print \"Leafs count (model 7):\", count_leaves(model_7)\n",
    "print \"Leafs count (model 8):\", count_leaves(model_8)\n",
    "print \"Leafs count (model 9):\", count_leaves(model_9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quiz Question:** Using the results obtained in this section, which model (**model_7**, **model_8**, or **model_9**) would you choose to use?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model 8"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
